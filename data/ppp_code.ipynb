{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45967,"status":"ok","timestamp":1714164263989,"user":{"displayName":"Luna","userId":"05502175004773324704"},"user_tz":240},"id":"Yb4GePdMlP4L","outputId":"e650a65a-15b5-4fd1-c00b-4737e81f7e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting azure-storage-blob\n","  Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/394.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob)\n","  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (42.0.5)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.11.0)\n","Collecting isodate>=0.6.1 (from azure-storage-blob)\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2024.2.2)\n","Installing collected packages: isodate, azure-core, azure-storage-blob\n","Successfully installed azure-core-1.30.1 azure-storage-blob-12.19.1 isodate-0.6.1\n","Collecting boto3\n","  Downloading boto3-1.34.93-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.35.0,>=1.34.93 (from boto3)\n","  Downloading botocore-1.34.93-py3-none-any.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n","  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.8.2)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.93->boto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.34.93 botocore-1.34.93 jmespath-1.0.1 s3transfer-0.10.1\n","Requirement already satisfied: google_cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google_cloud-storage) (2.27.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google_cloud-storage) (2.11.1)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google_cloud-storage) (2.3.3)\n","Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google_cloud-storage) (2.7.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google_cloud-storage) (2.31.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud-storage) (1.63.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud-storage) (3.20.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google_cloud-storage) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google_cloud-storage) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google_cloud-storage) (4.9)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google_cloud-storage) (1.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google_cloud-storage) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google_cloud-storage) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google_cloud-storage) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google_cloud-storage) (2024.2.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google_cloud-storage) (0.6.0)\n"]}],"source":["!pip install azure-storage-blob\n","!pip install boto3\n","!pip install google_cloud-storage"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":169,"status":"ok","timestamp":1714165450238,"user":{"displayName":"Luna","userId":"05502175004773324704"},"user_tz":240},"id":"j-C6PGSxe8F7"},"outputs":[],"source":["# import librairies\n","import pandas as pd\n","import numpy as np\n","import json\n","import requests\n","import boto3\n","from azure.storage.blob import BlobServiceClient, ContainerClient\n","from google.cloud import storage\n","from io import StringIO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"executionInfo":{"elapsed":3352,"status":"error","timestamp":1713919389685,"user":{"displayName":"Luna","userId":"05502175004773324704"},"user_tz":240},"id":"kG_TreLMhwth","outputId":"2141282d-ce91-472a-dc0c-052e71d50332"},"outputs":[{"ename":"ArrowInvalid","evalue":"Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7814f4c89565>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/4fc8e993-c3b9-4eb2-b9bb-dfbde9b1fb6f/download/public_up_to_150k_8_230930.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pyarrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2954\u001b[0m             )\n\u001b[1;32m   2955\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2956\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   2957\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m                 \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m             self._dataset = ds.FileSystemDataset(\n\u001b[0;32m-> 2496\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."]}],"source":["#import data\n","URL = \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/4fc8e993-c3b9-4eb2-b9bb-dfbde9b1fb6f/download/public_up_to_150k_8_230930.csv\"\n","df_raw=pd.read_parquet(URL, engine='pyarrow')\n","df_raw.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PxuHe5jlNKh"},"outputs":[],"source":["print(df_raw.shape)# to know how many row and col we have"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAq2Qo2Tlmy5"},"outputs":[],"source":["print(df_raw.columns) # know col name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzdnhgOPlp9n"},"outputs":[],"source":["#drop some na value if we have\n","df_raw.dropna()\n","df_raw.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGR5zfL9lr9G"},"outputs":[],"source":["#checking if we successfull drop na value\n","df_raw.info()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":139,"status":"ok","timestamp":1714165909092,"user":{"displayName":"Luna","userId":"05502175004773324704"},"user_tz":240},"id":"9qSJHZzbltoe"},"outputs":[],"source":["# Function\n","\n","# Azure Functions\n","def azure_upload_blob(connect_str, container_name, blob_name, data):\n","    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n","    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n","    blob_client.upload_blob(data, overwrite=True)\n","    print(f\"Uploaded to Azure Blob: {blob_name}\")\n","\n","def azure_download_blob(connect_str, container_name, blob_name):\n","    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n","    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n","    download_stream = blob_client.download_blob()\n","    return download_stream.readall()\n","\n","# Google Cloud Functions\n","def google_upload_blob(bucket_name, source_file_name, destination_blob_name):\n","    storage_client = storage.Client()\n","    bucket = storage_client.bucket(bucket_name)\n","    blob = bucket.blob(destination_blob_name)\n","    blob.upload_from_filename(source_file_name)\n","    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n","\n","def google_download_blob(bucket_name, source_blob_name, destination_file_name):\n","    storage_client = storage.Client()\n","    bucket = storage_client.bucket(bucket_name)\n","    blob = bucket.blob(source_blob_name)\n","    blob.download_to_filename(destination_file_name)\n","    print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")\n","\n","# AWS Functions\n","def aws_upload_file(file_name, bucket, object_name=None):\n","    if object_name is None:\n","        object_name = os.path.basename(file_name)\n","    s3_client = boto3.client('s3')\n","    response = s3_client.upload_file(file_name, bucket, object_name)\n","    print(f\"Uploaded {file_name} to S3 bucket {bucket}.\")\n","\n","def aws_download_file(bucket, object_name, file_name):\n","    s3_client = boto3.client('s3')\n","    s3_client.download_file(bucket, object_name, file_name)\n","    print(f\"Downloaded {object_name} from S3 bucket {bucket}.\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":677851,"status":"ok","timestamp":1714166880991,"user":{"displayName":"Luna","userId":"05502175004773324704"},"user_tz":240},"id":"XZzd_OkoQA2U","outputId":"a1bd41e5-7087-42b2-9197-4351fc049946"},"outputs":[{"name":"stdout","output_type":"stream","text":["Uploaded public_up_to_150k_1_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_2_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_3_230930.csv to Azure Blob Storage in container projectdata.\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-13-9055b598ce06>:35: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_raw = pd.read_csv(data_source_url)\n"]},{"name":"stdout","output_type":"stream","text":["Uploaded public_up_to_150k_4_230930.csv to Azure Blob Storage in container projectdata.\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-13-9055b598ce06>:35: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_raw = pd.read_csv(data_source_url)\n"]},{"name":"stdout","output_type":"stream","text":["Uploaded public_up_to_150k_5_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_6_230930.csv to Azure Blob Storage in container projectdata.\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-13-9055b598ce06>:35: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_raw = pd.read_csv(data_source_url)\n"]},{"name":"stdout","output_type":"stream","text":["Uploaded public_up_to_150k_7_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_8_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_9_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_10_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_11_230930.csv to Azure Blob Storage in container projectdata.\n","Uploaded public_up_to_150k_12_230930.csv to Azure Blob Storage in container projectdata.\n"]}],"source":["import pandas as pd\n","import json\n","from io import StringIO\n","from azure.storage.blob import BlobServiceClient\n","\n","\n","# Specify the path to your JSON configuration file\n","config_file_path = 'config.json'\n","\n","# Load the JSON configuration file\n","with open(config_file_path, 'r') as config_file:\n","    config = json.load(config_file)\n","\n","# Azure Blob Storage configuration\n","CONNECTION_STRING_AZURE_STORAGE = config[\"connectionString\"]\n","CONTAINER_AZURE = 'projectdata'\n","\n","# List of data source URLs\n","data_source_urls = [\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/a7fa66f4-fd2e-433c-8ef9-59780ef60ae5/download/public_up_to_150k_1_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/7d2308a8-0ac1-48a8-b21b-f9eb373ac417/download/public_up_to_150k_2_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/5158aae1-066d-4d01-a226-e44ecc9bdda7/download/public_up_to_150k_3_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/d888bab1-da5b-46f2-bed2-a052d48af246/download/public_up_to_150k_4_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/ee12d751-2bb4-4343-8330-32311ae4e7c7/download/public_up_to_150k_5_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/27b874d9-a059-4296-bb74-374294c48616/download/public_up_to_150k_6_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/434efae0-016a-48da-92dc-c6f113d827c1/download/public_up_to_150k_7_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/4fc8e993-c3b9-4eb2-b9bb-dfbde9b1fb6f/download/public_up_to_150k_8_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/7f9c6867-2b55-472e-a4f3-fd0f5f27f790/download/public_up_to_150k_9_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/a8f2c8b2-facb-4e97-ad5f-7c8736c8b4b6/download/public_up_to_150k_10_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/6f9787a3-afd6-45b2-b78e-ad0dc097c1c3/download/public_up_to_150k_11_230930.csv\",\n","    \"https://data.sba.gov/dataset/8aa276e2-6cab-4f86-aca4-a7dde42adf24/resource/b6528428-fbd9-4ca6-ae08-9e3416f8ee7f/download/public_up_to_150k_12_230930.csv\"\n","]\n","\n","for idx, data_source_url in enumerate(data_source_urls, start=1):\n","    # Download data from the URL and load it into a DataFrame\n","    df_raw = pd.read_csv(data_source_url)\n","\n","    # Convert DataFrame to CSV\n","    output = StringIO()\n","    df_raw.to_csv(output, index=False)\n","    data = output.getvalue()\n","    output.close()\n","\n","    # Blob name based on index\n","    blob_name = f\"public_up_to_150k_{idx}_230930.csv\"\n","\n","    # Create the BlobServiceClient object\n","    blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n","\n","    # Get a blob client using the container name and blob name\n","    blob_client = blob_service_client.get_blob_client(container=CONTAINER_AZURE, blob=blob_name)\n","\n","    # Upload the CSV data\n","    blob_client.upload_blob(data, overwrite=True)\n","\n","    print(f\"Uploaded {blob_name} to Azure Blob Storage in container {CONTAINER_AZURE}.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import zipfile\n","\n","# Download the ZIP file\n","url = \"https://apps.bea.gov/regional/zip/SQGDP.zip\"\n","response = requests.get(url)\n","\n","# Save the ZIP file\n","zip_file_path = \"SQGDP.zip\"\n","with open(zip_file_path, \"wb\") as f:\n","    f.write(response.content)\n","\n","# Extract the CSV file from the ZIP archive\n","with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n","    csv_file_name = \"SQGDP2__ALL_AREAS_2018_2023.csv\"\n","    zip_ref.extract(csv_file_name)\n","\n","# Parse the CSV file using pandas\n","df = pd.read_csv(csv_file_name)\n","\n","config_file_path = 'config.json'\n","\n","with open(config_file_path, 'r') as config_file:\n","    config = json.load(config_file)\n","\n","# Upload the CSV file to Azure Blob Storage\n","connection_string = config['connectionString']\n","container_name = \"projectdata\"\n","blob_name = \"SQGDP2__ALL_AREAS_2018_2023.csv\"\n","\n","blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n","container_client = blob_service_client.get_container_client(container_name)\n","\n","with open(csv_file_name, \"rb\") as data:\n","    container_client.upload_blob(name=blob_name, data=data)\n","\n","print(\"CSV file uploaded to Azure Blob Storage.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://www.census.gov/naics/2022NAICS/2022_NAICS_Descriptions.xlsx\"\n","response = requests.get(url)\n","\n","# Save the Excel file\n","excel_file_path = \"2022_NAICS_Descriptions.xlsx\"\n","with open(excel_file_path, \"wb\") as f:\n","    f.write(response.content)\n","\n","# Parse the Excel file using pandas\n","df = pd.read_excel(excel_file_path)\n","\n","config_file_path = 'config.json'\n","\n","with open(config_file_path, 'r') as config_file:\n","    config = json.load(config_file)\n","\n","# Upload the CSV file to Azure Blob Storage\n","connection_string = config['connectionString']\n","container_name = \"projectdata\"\n","blob_name = \"2022_NAICS_Descriptions.xlsx\"\n","\n","blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n","container_client = blob_service_client.get_container_client(container_name)\n","\n","with open(excel_file_path, \"rb\") as data:\n","    container_client.upload_blob(name=blob_name, data=data)\n","\n","print(\"Excel file uploaded to Azure Blob Storage.\")"]},{"cell_type":"markdown","metadata":{},"source":["#Downloading data from Azure Container"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config_file_path = 'config.json'\n","\n","#load the JSON configuration file\n","with open(config_file_path, 'r') as config_file:\n","  config = json.load(config_file)\n","\n","#print the configuration\n","#Connection_STRING = config['CONNECTION_STRING_AZURE_STORAGE']\n","\n","CONNECTION_STRING_AZURE_STORAGE = config['connectionString']\n","CONTAINER_AZURE = 'projectdata'\n","blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n","container_client = blob_service_client.get_container_client(CONTAINER_AZURE)\n","ppp_data = []\n","gdp_data = []\n","naics = []\n","blob_list = container_client.list_blobs()\n","for blob in blob_list:\n","  if blob.name == \"2022_NAICS_Descriptions.xlsx\" or blob.name == \"SQGDP2__ALL_AREAS_2018_2023.csv\":\n","    if blob.name == \"2022_NAICS_Descriptions.xlsx\":\n","      blob_client = container_client.get_blob_client(blob = blob.name)\n","      blob_data = blob_client.download_blob()\n","      blob_content = blob_data.readall()\n","      df = pd.read_excel(blob_content)\n","      naics.append(df)\n","    elif blob.name == \"SQGDP2__ALL_AREAS_2018_2023.csv\":\n","      blob_client = container_client.get_blob_client(blob = blob.name)\n","      blob_data = blob_client.download_blob()\n","      blob_content = blob_data.readall().decode('utf-8')\n","      df1 = pd.read_csv(StringIO(blob_content))\n","      gdp_data.append(df1)\n","  else:\n","    blob_client = container_client.get_blob_client(blob = blob.name)\n","    blob_data = blob_client.download_blob()\n","    blob_content = blob_data.readall().decode('utf-8')\n","    df2 = pd.read_csv(StringIO(blob_content))\n","    ppp_data.append(df2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_naics = pd.concat(naics, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_ppp = pd.concat(ppp_data, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_gdp = pd.concat(gdp_data, ignore_index=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMp1xp0u5R/vZtBx4FRtxIs","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
